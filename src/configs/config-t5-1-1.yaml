learning_rate: 0.3
optimizer: Adafactor
batch_size: 32
epochs: 3
training_steps: 262144
eval_steps: 5000
save_steps: 5000
warm_init: True
weight_decay: 0.00001
num_warmup_steps: 0
language: english
model_name: liangtaiwan/t5-v1_1-lm100k-base
# model_name: ../results/t5-v1_1-lm100k-base-mnli/best_model
output_path: ../results
# output_path: ../results/100size
prompt_init_text: "Answer True or False: "
init_type: sampled
num_virtual_tokens: 100
eval_strategy: steps
gradient_steps: 100
fp16: True
padding: max_length
truncation: True