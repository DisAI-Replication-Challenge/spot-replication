learning_rate: 0.3
optimizer: Adafactor
batch_size: 32
epochs: 3
training_steps: 262144
eval_steps: 500
save_steps: 500
warm_init: True
weight_decay: 0.00001
num_warmup_steps: 0
# model_name: liangtaiwan/t5-v1_1-lm100k-base
model_name: ../results/t5-v1_1-lm100k-base-mnli/best_model
output_path: ../results/t5v1-1-mnli
# output_path: ../results/100size
prompt_init_text: "Answer True or False: "
eval_strategy: steps
gradient_steps: 100
fp16: True
padding: max_length
truncation: True